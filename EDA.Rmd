---
title: "EDA"
author: "Matheus Leal"
date: "06 de outubro de 2019"
output:
  prettydoc::html_pretty:
    theme: leonids
    highlight: github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
	             cache = FALSE,
               prompt = FALSE,
               tidy = FALSE,
               comment = NA,
               message = FALSE,
               warning = FALSE)
```

```{r}
library(tidyverse)
library(hrbrthemes)
library(plotly)
library(GGally)
library(broom)
library(modelr)
```

```{r}
notas_gerais <- read_csv("notas_gerais.csv")
```

Foi feita uma análise exploratória dos dados sobre o desempenho dos alunos da disciplina Laboratório de Programação II do Curso de Ciência da Computação da UFCG. São 441 observações, que se distribuem em 5 períodos letivos (2017.1 - 2019.1). Como cada período possuía um método de avaliação diferente, alguns com diferenças sutis, outros com diferenças mais expressivas, foi necessário, em determinados momentos, dividir nossa análise por período.

##Desempenho

O primeiro passo tomado foi analisar o desempenho das turmas nesses períodos para identificar discrepâncias e enxergar padrões.

```{r}
notas_com_diferencas <- notas_gerais %>% 
  mutate(provas_labs = media_provas - media_labs,
         provas_projeto = media_provas - projeto,
         projeto_labs = projeto - media_labs,
         provas_praticas_vs_teoricas = media_provas - p2)
```

Consideramos nossa primeira medida a média parcial. Ela nos dá um overview do desempenho das turmas, pois considera todas a avaliações excluindo a avaliação final.

```{r, fig.height=7, fig.width=9}
p <- notas_com_diferencas %>% ggplot(aes(periodo,
                        media_parcial, 
                        color=periodo,
                        label = "")) +
             scale_colour_brewer(palette="Set1") +
             hrbrthemes::theme_ipsum_rc(grid="X") +
               theme(legend.position = "top") +
             geom_jitter(width = 0.05) +
             geom_point(size = 7, 
                        stat = 'summary', 
                        fun.y = function(x) median(x, na.rm = TRUE), 
                        color = "grey", 
                        alpha = 0.8) +    
             labs(
              x = NULL, y = NULL, fill = NULL,
              title = "Média parcial"
             )
            
p
```

Observando `media_parcial` vemos o período 2017.2 como aquele com o melhor desempenho mediano, onde, desde então, o desempenho vem caindo, tendo o 2019.2 o menor dentre todos. Vamos destrinchar esse desempenho entre as principais atividades avaliativas: Provas, laboratórios e projeto.

```{r, fig.height=7, fig.width=9}
p <- notas_com_diferencas %>% ggplot(aes(periodo,
                        media_labs, 
                        fill = periodo)) +
             scale_fill_brewer(palette="Set1") +
             hrbrthemes::theme_ipsum_rc(grid="X") +
             geom_violin(alpha = 0.5) +
             geom_boxplot(width=0.1, fill="grey", color="white", alpha= 0.3)+
             theme(legend.position = "top") +
             labs(
              x = NULL, y = "Desempenho", fill = NULL,
              title = "Desempenho nos laboratórios",
              subtitle = "Desempenho dos alunos nos laboratórios por período",
              caption = ""
             )
            
p
```

```{r, fig.height=7, fig.width=9}
p <- notas_com_diferencas %>% ggplot(aes(periodo,
                        media_provas, 
                        fill = periodo)) +
             scale_fill_brewer(palette="Set1") +
             hrbrthemes::theme_ipsum_rc(grid="X") +
             geom_violin(alpha = 0.5) +
             geom_boxplot(width=0.1, fill="grey", color="white", alpha= 0.3)+
             theme(legend.position = "top") +
             labs(
              x = NULL, y = "Desempenho", fill = NULL,
              title = "Desempenho nas provas",
              subtitle = "Desempenho dos alunos nas provas por período",
              caption = ""
             )
            
p
```

```{r, fig.height=7, fig.width=9}
p <- notas_com_diferencas %>% ggplot(aes(periodo,
                        projeto, 
                        fill = periodo)) +
             scale_fill_brewer(palette="Set1") +
             hrbrthemes::theme_ipsum_rc(grid="X") +
             geom_violin(alpha = 0.5) +
             geom_boxplot(width=0.05, fill="grey", color="white", alpha= 0.3)+
             theme(legend.position = "top") +
             labs(
              x = NULL, y = "Desempenho", fill = NULL,
              title = "Desempenho no projeto",
              subtitle = "Desempenho dos alunos no projeto por período",
              caption = ""
             )
            
p
```

##Relações

Para investigarmos as relações entre as avaliações, primeiro vejamos o correlograma das variáveis:

###Correlograma

```{r, fig.height=8, fig.width=10}
numeric_notas_gerais <- notas_gerais %>%    select(-id, -periodo,-professor,-elab_p1,-elab_p2,-elab_p3,-elab_repo,
      -correcao_p1,-correcao_p2,-correcao_p3,-correcao_repo)
corr <- cor(numeric_notas_gerais, use = "pairwise.complete.obs")
ggcorr(numeric_notas_gerais,
    nbreaks = 10,
    label = TRUE,
    label_round = 2,
    label_size = 3,
    hjust = 0.75,
    size = 4,
    color = "grey50")
```

Primeiro, devemos considerar que as variáveis `media_provas`, `media_labs`,  `media_parcial` e `media_final` são constituídas por outras variáveis que também estão no correlograma, portanto, não devemos levar em conta a correlação entre essas:

Constituições:

`media_provas`: `prova_1`, `prova_2`, `prova_3` e/ou `reposicao`. 

`media_labs`: `lab_1`, `lab_2`, `lab_3`, `lab_4` e `lab_5`. 

`media_parcial`: `media_provas`, `media_labs`, `projeto`, `p2` e `minitestes`. 

`media_final`: `media_parcial` e `prova_final`. 


Tendo isso em mente, podemos destacar a correlação entre `p2`, que representa a média das provas teóricas, e as variáveis que representam as provas práticas, em especial `prova_3` (0.7681678), assim como a variável composta delas `media_provas` (0.8130245). A variável `minitestes` tem uma correlação consideravelmente alta com quase todas as outras variáveis, destacando-se `media_provas` (0.8503633). A `media_labs` possui correlação entre 0.6 e 0.8 com diversas variáveis, destacaremos com `minitestes` (0.7894896), pois a correlação entre `minitestes` e `media_labs` deveria ser maior que `minitestes` e `media_provas`, tendo em vista que os minitestes e laboratórios são avaliações elaboradas para serem correspondentes. Por fim, a variável `projeto` não mostra uma correlação expressiva com nenhuma outra variável.

###Se aprofundando

Tendo estudado a matriz de correlações, nos aprofundamos naquela que se mostrou a informação mais interessantes: Parece existir uma relação entre a média das provas práticas e a média das provas teóricas. Lembrando que o correlograma foi construído utilizando o método de **pearson**. Caso tivéssemos utilizado o método de **spearman** - que utiliza ranks - para encontrar a correlação entre as duas variável, encontraríamos um resultado bem semelhante:

```{r}
notas_gerais %>% 
  filter(!is.na(media_provas), !is.na(p2)) %>% 
  summarise(
    pearson = cor(media_provas, p2, method = "pearson"), 
    spearman = cor(media_provas, p2, method = "spearman"))
```

O gráfico de dispersão:

```{r, fig.height=7, fig.width=9}
p <- ggplot(notas_com_diferencas, aes(x=media_provas, y=p2)) +
  geom_point() +
  hrbrthemes::theme_ipsum_rc(grid=FALSE) + 
  labs(
  x = "Média das provas práticas", y = "Média das provas teóricas", fill = NULL,
  title = "Desempenho nas provas práticas vs teóricas"
  )
p
```

Com a linha do modelo de regressão linear simples:

```{r, fig.height=7, fig.width=9}
p <- ggplot(notas_com_diferencas, aes(x=media_provas, y=p2)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  hrbrthemes::theme_ipsum_rc(grid=FALSE) + 
  labs(
  x = "Média das provas práticas", y = "Média das provas teóricas", fill = NULL,
  title = "Desempenho nas provas práticas vs teóricas"
  )
p
```

###O modelo

```{r}
mod <- lm(media_provas ~ p2, 
          data = notas_gerais)
tidy(mod)
```
```{r}
glance(mod)
```

O formato do modelo encontrado foi: **media_provas** = 0.26 + 0.97***(p2)** que explica 66% da variável resposta (R² = 0.6610089). 

Vejamos, então, o que o modelo estima para cada ponto de media_provas.

```{r, fig.height=7, fig.width=9}
notas_gerais %>% 
  select(media_provas, p2) %>% 
  add_predictions(model = mod) %>% # add o que o modelo estima p cada media_provas
  ggplot(mapping = aes(x = media_provas, y = p2)) + 
  geom_point() + 
  geom_line(aes(y = pred), colour = "darkblue")  + 
  geom_smooth(method = "lm", se = FALSE, color="red") +
  hrbrthemes::theme_ipsum_rc(grid=FALSE) +
  labs(
  x = "Média das provas práticas", y = "Média das provas teóricas", fill = NULL,
  title = "O que o modelo estima para cada ponto em media_provas"
  )
```

E o resíduo do modelo:

```{r, fig.height=7, fig.width=9}
notas_gerais %>% 
  add_residuals(model = mod) %>% 
  ggplot(aes(media_provas, resid)) + 
  geom_point() + 
  geom_hline(yintercept = 0, colour = "blue") +
  hrbrthemes::theme_ipsum_rc(grid=FALSE) +
  labs(
  x = "Média das provas práticas", y = "Resíduo", fill = NULL,
  title = "Resíduo do modelo"
  )
```

##Diferença entre avaliações

As diferenças entre as avaliação nos diz em qual avaliação o aluno teve melhor resultado e o quanto. A partir dessas diferenças, podemos identificar alunos com notas muito discrepantes e em quais atividades isso ocorre.

```{r, fig.height=7, fig.width=9}
p <- notas_com_diferencas %>% ggplot(aes(periodo,
                        provas_praticas_vs_teoricas, 
                        color=periodo,
                        label = "")) +
             scale_colour_brewer(palette="Set1") +
             hrbrthemes::theme_ipsum_rc(grid="X") +
               theme(legend.position = "top") +
             ggbeeswarm::geom_quasirandom(width = .4) +
             labs(
              x = NULL, y = NULL, fill = NULL,
              title = "Provas práticas - provas teóricas"
             )
            
p
```

```{r, fig.height=7, fig.width=9}
p <- notas_com_diferencas %>% ggplot(aes(periodo,
                        provas_labs, 
                        color=periodo,
                        label = "")) +
             scale_colour_brewer(palette="Set1") +
             hrbrthemes::theme_ipsum_rc(grid="X") +
               theme(legend.position = "top") +
             ggbeeswarm::geom_quasirandom(width = .4) +
             labs(
              x = NULL, y = NULL, fill = NULL,
              title = "Provas práticas - laboratórios"
             )
            
p
```

Os laboratórios e as provas práticas são duas das principais atividades avaliativas da disciplina e, observando o gráfico da dispersão dessa diferença ao longo dos períodos, podemos notar que temos no 19.2 uma maior concentração em torno do 0, ou seja, os alunos estão tendo desempenho semelhante nas duas avaliações. Vejamos algumas medidas que podem nos ajudar a verificar se isso é verdade.

```{r}
desvio_padrao_periodos <- notas_com_diferencas %>% 
  select(periodo, provas_labs) %>% 
  na.omit() %>%
  group_by(periodo) %>% 
  summarise(desvio_padrao = sd(provas_labs), mediana = median(provas_labs), variancia = var(provas_labs))

desvio_padrao_periodos

```

Os períodos 17.2 e 19.2 mostram uma maior semelhança no desempenho dos alunos para essas atividades. Se aprofundando um pouco mais na relação dessas avaliações, podemos calcular sua correlação, focando, agora, no último período, visto que possui o segundo desvio padrão mais baixo e é aquele com a metodologia de avaliação mais próxima da atual.

```{r}
notas_gerais %>% filter(periodo == "2019/1") %>% 
  filter(!is.na(media_provas), !is.na(media_labs)) %>% 
  summarise(
    pearson = cor(media_provas, media_labs, method = "pearson"), 
    spearman = cor(media_provas, media_labs, method = "spearman"))
```

Medidas semelhantes e relativamente mais altas quando consideramos o panorama geral.

O gráfico de dispersão:

```{r, fig.height=7, fig.width=9}
p <- ggplot(notas_com_diferencas %>% filter(periodo == "2019/1"), aes(x=media_provas, y=media_labs)) +
  geom_point() +
  hrbrthemes::theme_ipsum_rc(grid=FALSE) + 
  labs(
  x = "Média das provas práticas", y = "Média dos laboratórios", fill = NULL,
  title = "Desempenho nas provas práticas vs laboratório"
  )
p
```

Com a linha do modelo de regressão linear simples:

```{r, fig.height=7, fig.width=9}
p <- ggplot(notas_com_diferencas %>% filter(periodo == "2019/1"), aes(x=media_provas, y=media_labs)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  hrbrthemes::theme_ipsum_rc(grid=FALSE) + 
  labs(
  x = "Média das provas práticas", y = "Média dos laboratórios", fill = NULL,
  title = "Desempenho nas provas práticas vs laboratório"
  )
p
```

### O modelo

```{r}
mod <- lm(media_provas ~ media_labs, 
          data = notas_com_diferencas %>% filter(periodo == "2019/1"))
tidy(mod)
```
```{r}
glance(mod)
```

O formato do modelo encontrado foi: **media_provas** = -0.297 + 0.9***(media_labs)** que explica 66% da variável resposta (R² = 0.664019). 

O resíduo do modelo:

```{r, fig.height=7, fig.width=9}
notas_gerais %>% 
  filter(periodo == "2019/1") %>% 
  add_residuals(model = mod) %>% 
  ggplot(aes(media_provas, resid)) + 
  geom_point() + 
  geom_hline(yintercept = 0, colour = "blue") +
  hrbrthemes::theme_ipsum_rc(grid=FALSE) +
  labs(
  x = "Média das provas práticas", y = "Resíduo", fill = NULL,
  title = "Resíduo do modelo"
  )
```

Voltando para as demais distâncias:

```{r, fig.height=7, fig.width=9}
p <- notas_com_diferencas %>% ggplot(aes(periodo,
                        provas_projeto, 
                        color=periodo,
                        label = "")) +
             scale_colour_brewer(palette="Set1") +
             hrbrthemes::theme_ipsum_rc(grid="X") +
               theme(legend.position = "top") +
             ggbeeswarm::geom_quasirandom(width = .4)+
             labs(
              x = NULL, y = NULL, fill = NULL,
              title = "Provas práticas - projeto"
             )
            
p
```

```{r, fig.height=7, fig.width=9}
p <- notas_com_diferencas %>% ggplot(aes(periodo,
                        projeto_labs, 
                        color=periodo,
                        label = "")) +
             scale_colour_brewer(palette="Set1") +
             hrbrthemes::theme_ipsum_rc(grid="X") +
               theme(legend.position = "top") +
             ggbeeswarm::geom_quasirandom(width = .4)+
             labs(
              x = NULL, y = NULL, fill = NULL,
              title = "Projeto - labortatórios"
             )
            
p
```

Quanto mais distante de 0, maior a diferença entre as avaliações. Podemos agora definir perfis a partir dessas diferenças.

##Agrupamento

### Between/totss

Outra medida comumente usada no kmeans é _comparar a distância (quadrática) entre o centro dos clusters e o centro dos dados com a distância (quadrática) entre os pontos todos nos dados e o centro dos dados_. 

Quebrando essa ideia para ficar mais fácil de entender: 

Primeiro, o _centro dos dados_ é um ponto imaginário na média de todas as variáveis. É um ponto que está no meio dos dados. Em uma situação onde cada ponto é um grupo (e os grupos são os mais coesos possíveis), a soma das distâncias dos grupos para o centro dos dados é igual à soma da distância dos pontos para o centro dos dados. Generalizando: se houver estrutura de grupos e ela estiver capturada pelo agrupamento, o somatório da distância do centro de cada grupo para o centro geral dos dados será um valor alto.

Para medir para quais valores de `k` isso acontece, calculamos a _distância do centro de cada cluster para o centro dos dados_ e multiplicamos pelo número de pontos nesse cluster. Somando esse valor para todos os clusters, temos `betweenss` abaixo. 

Se esse valor for próximo do somatório total das distâncias dos pontos para o centro dos dados (`totss`), os pontos estão próximos do centro de seu cluster. Essa proporção pode ser usada para definir um bom valor de `k`. Quando ela para de crescer, para de valer à pena aumentar `k`.


```{r}
difs <- notas_com_diferencas %>% select(provas_praticas_vs_teoricas, periodo) %>% na.omit()
set.seed(123)
explorando_k = tibble(k = 1:15) %>%
    mutate(agrupamento = map(k, ~ kmeans(
        select(difs, provas_praticas_vs_teoricas),
        centers = .
    ) %>% glance())) %>%
    unnest(agrupamento)
explorando_k %>% 
    ggplot(aes(x = k, y = betweenss / totss)) + 
    geom_line() + 
    geom_point() +
    hrbrthemes::theme_ipsum_rc() +
    labs(
      x = "K", y = "Betweenss/totss", fill = NULL,
      title = "Provas práticas - provas teóricas"
    )
```

O bom valor de k parece ser 3, que vai ser o número de clusters para o nosso algoritmo de agrupamento.

###K-means

```{r}
n_clusters = 3
km = difs %>% select(provas_praticas_vs_teoricas) %>%
    kmeans(centers = n_clusters, nstart = 20)
agrupado = km %>% 
    augment(difs)
```

O algoritmo nos da a seguinte distribuição para os grupos:

```{r, fig.height=7, fig.width=9}
p <- agrupado %>% ggplot(aes(periodo,
                        provas_praticas_vs_teoricas, 
                        color=.cluster,
                        label = "")) +
             scale_colour_brewer(palette="Set1") +
             hrbrthemes::theme_ipsum_rc(grid="X") +
               theme(legend.position = "top") +
             ggbeeswarm::geom_quasirandom(width = .4) +
             labs(
              x = NULL, y = NULL, fill = NULL,
              title = "Provas práticas - provas teóricas"
             ) +
    labs(
      x = NULL, y = NULL, fill = NULL,
      title = "Provas práticas - provas teóricas"
    )
            
p
```

Algumas medidas para os grupos:

```{r}
desvio_padrao_grupos<- agrupado %>% 
  select(.cluster, provas_praticas_vs_teoricas) %>% 
  na.omit() %>%
  group_by(.cluster) %>% 
  summarise(desvio_padrao = sd(provas_praticas_vs_teoricas), mediana = median(provas_praticas_vs_teoricas), variancia = var(provas_praticas_vs_teoricas))

desvio_padrao_grupos

```

```{r}
difs <- notas_com_diferencas %>% select(provas_labs, periodo) %>% na.omit()
set.seed(123)
explorando_k = tibble(k = 1:15) %>%
    mutate(agrupamento = map(k, ~ kmeans(
        select(difs, provas_labs),
        centers = .
    ) %>% glance())) %>%
    unnest(agrupamento)
explorando_k %>% 
    ggplot(aes(x = k, y = betweenss / totss)) + 
    geom_line() + 
    geom_point() +
    hrbrthemes::theme_ipsum_rc() +
    labs(
      x = "K", y = "Betweenss/totss", fill = NULL,
      title = "Provas práticas - laboratórios"
    )
```

O bom valor de k parece ser 4, que vai ser o número de clusters para o nosso algoritmo de agrupamento.

```{r}
n_clusters = 4
km = difs %>% select(provas_labs) %>%
    kmeans(centers = n_clusters, nstart = 20)
agrupado = km %>% 
    augment(difs)
```

O algoritmo nos da a seguinte distribuição para os grupos:

```{r, fig.height=7, fig.width=9}
p <- agrupado %>% ggplot(aes(periodo,
                        provas_labs, 
                        color=.cluster,
                        label = "")) +
             scale_colour_brewer(palette="Set1") +
             hrbrthemes::theme_ipsum_rc(grid="X") +
               theme(legend.position = "top") +
             ggbeeswarm::geom_quasirandom(width = .4) +
             labs(
              x = NULL, y = NULL, fill = NULL,
              title = "Provas práticas - laboratórios"
             ) 
            
p
```

Algumas medidas para os grupos:

```{r}
desvio_padrao_grupos<- agrupado %>% 
  select(.cluster, provas_labs) %>% 
  na.omit() %>%
  group_by(.cluster) %>% 
  summarise(desvio_padrao = sd(provas_labs), mediana = median(provas_labs), variancia = var(provas_labs))

desvio_padrao_grupos

```

O grupo 1 possui uma mediana de -2.83, uma diferença de quase 3 pontos da media das provas práticas para a media dos laboratórios.

```{r}
difs <- notas_com_diferencas %>% select(projeto_labs, periodo) %>% na.omit()
set.seed(123)
explorando_k = tibble(k = 1:15) %>%
    mutate(agrupamento = map(k, ~ kmeans(
        select(difs, projeto_labs),
        centers = .
    ) %>% glance())) %>%
    unnest(agrupamento)
explorando_k %>% 
    ggplot(aes(x = k, y = betweenss / totss)) + 
    geom_line() + 
    geom_point() +
    hrbrthemes::theme_ipsum_rc() +
    labs(
      x = "K", y = "Betweenss/totss", fill = NULL,
      title = "Projeto - laboratórios"
    )
```

O bom valor de k parece ser 4, que vai ser o número de clusters para o nosso algoritmo de agrupamento.

```{r}
n_clusters = 4
km = difs %>% select(projeto_labs) %>%
    kmeans(centers = n_clusters, nstart = 20)
agrupado = km %>% 
    augment(difs)
```

O algoritmo nos da a seguinte distribuição para os grupos:

```{r, fig.height=7, fig.width=9}
p <- agrupado %>% ggplot(aes(periodo,
                        projeto_labs, 
                        color=.cluster,
                        label = "")) +
             scale_colour_brewer(palette="Set1") +
             hrbrthemes::theme_ipsum_rc(grid="X") +
               theme(legend.position = "top") +
             ggbeeswarm::geom_quasirandom(width = .4) +
             labs(
              x = NULL, y = NULL, fill = NULL,
              title = "Projeto - laboratórios"
             ) 
            
p
```

Algumas medidas para os grupos:

```{r}
desvio_padrao_grupos<- agrupado %>% 
  select(.cluster, projeto_labs) %>% 
  na.omit() %>%
  group_by(.cluster) %>% 
  summarise(desvio_padrao = sd(projeto_labs), mediana = median(projeto_labs), variancia = var(projeto_labs))

desvio_padrao_grupos

```


```{r}
difs <- notas_com_diferencas %>% select(provas_projeto, periodo) %>% na.omit()
set.seed(123)
explorando_k = tibble(k = 1:15) %>%
    mutate(agrupamento = map(k, ~ kmeans(
        select(difs, provas_projeto),
        centers = .
    ) %>% glance())) %>%
    unnest(agrupamento)
explorando_k %>% 
    ggplot(aes(x = k, y = betweenss / totss)) + 
    geom_line() + 
    geom_point() +
    hrbrthemes::theme_ipsum_rc() +
    labs(
      x = "K", y = "Betweenss/totss", fill = NULL,
      title = "Provas práticas - projeto"
    )
```

O bom valor de k parece ser 4, que vai ser o número de clusters para o nosso algoritmo de agrupamento.

```{r}
n_clusters = 4
km = difs %>% select(provas_projeto) %>%
    kmeans(centers = n_clusters, nstart = 20)
agrupado = km %>% 
    augment(difs)
```

O algoritmo nos da a seguinte distribuição para os grupos:

```{r, fig.height=7, fig.width=9}
p <- agrupado %>% ggplot(aes(periodo,
                        provas_projeto, 
                        color=.cluster,
                        label = "")) +
             scale_colour_brewer(palette="Set1") +
             hrbrthemes::theme_ipsum_rc(grid="X") +
               theme(legend.position = "top") +
             ggbeeswarm::geom_quasirandom(width = .4) +
             labs(
              x = NULL, y = NULL, fill = NULL,
              title = "Provas práticas - projeto"
             ) 
            
p
```

Algumas medidas para os grupos:

```{r}
desvio_padrao_grupos<- agrupado %>% 
  select(.cluster, provas_projeto) %>% 
  na.omit() %>%
  group_by(.cluster) %>% 
  summarise(desvio_padrao = sd(provas_projeto), mediana = median(provas_projeto), variancia = var(provas_projeto))

desvio_padrao_grupos

```

##Evolução dos grupos 2018.2



```{r}
difs <- notas_gerais %>% filter(periodo == "2018/2") %>% select(-id, -periodo,-professor,-elab_p1,-elab_p2,-elab_p3,-elab_repo,
                                                                -media_labs, -media_provas, -media_parcial, -correcao_p1,-correcao_p2,
                                                                -correcao_p3,-correcao_repo, - minitestes, -p2, -prova_final, -reposicao) %>% na.omit()
set.seed(123)
explorando_k = tibble(k = 1:15) %>%
    mutate(agrupamento = map(k, ~ kmeans(
        select(difs, everything()),
        centers = .
    ) %>% glance())) %>%
    unnest(agrupamento)
explorando_k %>% 
    ggplot(aes(x = k, y = betweenss / totss)) + 
    geom_line() + 
    geom_point() +
    hrbrthemes::theme_ipsum_rc() +
    labs(
      x = "K", y = "Betweenss/totss", fill = NULL,
      title = "Todas as avaliações"
    )
```

```{r}
n_clusters = 4
km = difs %>% kmeans(centers = n_clusters, nstart = 20)
agrupado = km %>% 
    augment(difs)
```


```{r, fig.width=12, fig.height=10}
evol <- agrupado %>% select(lab_1, lab_2, lab_3, prova_1, lab_4, lab_5, prova_2, prova_3, projeto, .cluster)
ggparcoord(evol, columns = 1:8, mapping=aes(color=as.factor( .cluster))) + 
  hrbrthemes::theme_ipsum_rc(grid="Y") +
  scale_colour_brewer(palette="Set1") +
  facet_wrap(. ~ .cluster, ncol=2) +
    labs(
      x = "Avaliações", y = "Z-score", fill = NULL, legend = NULL,
      title = "Evolução dos grupos de alunos na disciplina (4 grupos)"
    ) + theme(legend.position="none")
```

O bom valor de k parece ser 4, que vai ser o número de clusters para o nosso algoritmo de agrupamento.

```{r}
n_clusters = 6
km = difs %>% kmeans(centers = n_clusters, nstart = 20)
agrupado = km %>% 
    augment(difs)
```


```{r, fig.width=12, fig.height=10}
evol <- agrupado %>% select(lab_1, lab_2, lab_3, prova_1, lab_4, lab_5, prova_2, prova_3, projeto, .cluster)
ggparcoord(evol, columns = 1:8, mapping=aes(color=as.factor( .cluster))) + 
  hrbrthemes::theme_ipsum_rc(grid="Y") +
  scale_colour_brewer(palette="Set1") +
  facet_wrap(. ~ .cluster, ncol=2)  +
    labs(
      x = "Avaliações", y = "Z-score", fill = NULL, legend = NULL,
      title = "Evolução dos grupos de alunos na disciplina (6 grupos)"
    ) + theme(legend.position="none")
```

```{r}
n_clusters = 8
km = difs %>% kmeans(centers = n_clusters, nstart = 20)
agrupado = km %>% 
    augment(difs)
```


```{r, fig.width=12, fig.height=10}
evol <- agrupado %>% select(lab_1, lab_2, lab_3, prova_1, lab_4, lab_5, prova_2, prova_3, projeto, .cluster)
ggparcoord(evol, columns = 1:8, mapping=aes(color=as.factor( .cluster))) + 
  hrbrthemes::theme_ipsum_rc(grid="Y") +
  scale_colour_brewer(palette="Set1") +
  facet_wrap(. ~ .cluster, ncol=2)  +
    labs(
      x = "Avaliações", y = "Z-score", fill = NULL, legend = NULL,
      title = "Evolução dos grupos de alunos na disciplina (8 grupos)"
    ) + theme(legend.position="none")
```
